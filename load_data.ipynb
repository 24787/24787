{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = \"txt/\"\n",
    "k = 10\n",
    "d = 5\n",
    "t = 0.2\n",
    "matrix_l = []\n",
    "for i in range(100):\n",
    "    t_f = t*i\n",
    "    t_Str = \"{0:0.1f}\".format(t_f)\n",
    "    filename = dirName + \"mesh_20_10_\" + t_Str + \".txt\"\n",
    "    if i%5==0:\n",
    "        filename = dirName + \"mesh_20_10_\" + str(int(t_f)) + \".txt\"\n",
    "    f = open ( filename , 'r')\n",
    "    row_data = []\n",
    "    row_data = [ line.split() for line in f]\n",
    "\n",
    "    matrix_ind = np.array([])\n",
    "    matrix_ind.resize((21,11))\n",
    "    for i in range(len(row_data)):\n",
    "        col = int(row_data[i][0])\n",
    "        row = int(row_data[i][1])\n",
    "        val = float(row_data[i][2])\n",
    "        matrix_ind[col][row] = val\n",
    "    matrix_l.append(matrix_ind)\n",
    "matrix_arr = np.array(matrix_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125e0ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## %matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "plt.matshow(matrix_arr[99,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_l = []\n",
    "for i in range(14):\n",
    "    matrix_ten = np.copy(matrix_arr[(5*i):(5*i+5),:,:])\n",
    "    ten = torch.from_numpy(matrix_ten)\n",
    "    tensor_l.append(ten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/1875], Reconst Loss: 718.0637\n",
      "Epoch[2/15], Step [10/1875], Reconst Loss: 585.3138\n",
      "Epoch[3/15], Step [10/1875], Reconst Loss: 568.6040\n",
      "Epoch[4/15], Step [10/1875], Reconst Loss: 547.6005\n",
      "Epoch[5/15], Step [10/1875], Reconst Loss: 541.2262\n",
      "Epoch[6/15], Step [10/1875], Reconst Loss: 537.2120\n",
      "Epoch[7/15], Step [10/1875], Reconst Loss: 538.4861\n",
      "Epoch[8/15], Step [10/1875], Reconst Loss: 535.8786\n",
      "Epoch[9/15], Step [10/1875], Reconst Loss: 529.0530\n",
      "Epoch[10/15], Step [10/1875], Reconst Loss: 524.3148\n",
      "Epoch[11/15], Step [10/1875], Reconst Loss: 519.7081\n",
      "Epoch[12/15], Step [10/1875], Reconst Loss: 524.6273\n",
      "Epoch[13/15], Step [10/1875], Reconst Loss: 526.9177\n",
      "Epoch[14/15], Step [10/1875], Reconst Loss: 518.5338\n",
      "Epoch[15/15], Step [10/1875], Reconst Loss: 508.2985\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 231\n",
    "h_dim = 100\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 5\n",
    "learning_rate = 2e-3\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=231, h_dim=100, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(14):\n",
    "        # Forward pass\n",
    "        x = tensor_l[i]\n",
    "        x = x.float()\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 21, 11)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 21, 11), out.view(-1, 1, 21, 11)], dim=3)\n",
    "        if i == 1:\n",
    "            x_array = x_concat.numpy()[:, ::-1, :, :]\n",
    "#         save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAECCAYAAADgsVLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAACp9JREFUeJzt3bmSJGcVBeA/s5bururqnhnNaIZBREgyCLYQgYEBuMjgAfSOegMMEVjYWMhDRKAFoWU2zfRaS2LgEydvdEuF4vvsG39lZdWcTuPUnW4YhgYwVv9dXwDw/0l4ACXCAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkCJ8ABKhAdQIjyAkum3+WLv9u/5T2K+b/rJzZ857OLRbpK//rC7ha9feK2jrnO7jWfTc8e89w8273fJnCcPoER4ACXCAygRHkCJ8ABKhAdQIjyAEuEBlAgPoORbbZiO0a9W2dxykR96MM9nRzQCY7uwOXl1HR85XF7lsxcX0dzu8jI+c0wbtD84yAZns/jMbjLi798s/Pyv8nva+qiM2YbrdXxkl35PWmvDZhMO5memPHkAJcIDKBEeQInwAEqEB1AiPIAS4QGUCA+gRHgAJfvbMD3JGqa7+6fxmZtV2HBsrW0Pb75hOllnLb/JWd5G7J+fxbPds6wN2cY0TG9Btzi6ldkhbKN2m/zM1mX3tLvI7+nu7Dx//W26QzU/MuXJAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkDJ3tbTh+NssfHVw2V85sX9/O2uF2GVOxxrrbVJ2FA+fJ4vAD6c5vk/vQpr70+exme2Ln/97vQkG7wTzrXWticjquzh+x/iE1tcT2+rEdd5eZzPvngZzW2//Co+M+XJAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkDJ3tbTd6vDaO78Qf4Wzh7nWbleZSXlYUT8Ts+zKvNmka+67nb5RvjJs+ye3pauz27WdpG/p/XJPJ7dzbL3322yjeSttTZMss90ermNz5z9exPPtm147oifEaQ8eQAlwgMoER5AifAASoQHUCI8gBLhAZQID6BEeAAle9sw3ayy5uDla3n+XTzKm4Pbe9my3G6Sr8u9Pstu926WfyzT83z28Dhvbt6KaXat22W+APr6NH//L97KmrvHn45pmGZzx5/kDdPtab4seXoebtUeRiy1DnnyAEqEB1AiPIAS4QGUCA+gRHgAJcIDKBEeQInwAEqEB1Cyt/X09TK7tKt7+ZnDw6t49vH9F9HcfJLXjr9+tYzmzrar+Myrp/my5O1RVvse8xel67MFwK21tjs9jubWp3k9fb3IX38Ttr7PHuV3YPFVVmW/vJ8val58NmIB8uS7+/vvyQMoER5AifAASoQHUCI8gBLhAZQID6BEeAAlwgMoER5Ayd7W0zdHWe34+iTfdP3g3st49md3v4jmjibX8Zkfz7Mu/d8u8irzerWIZ7eHWZV9zF+UYZdvjx+Os/d1vcor9+ev51fbhb8kuHiYv6fdQfb6B0/zM7tdvj19eZ5t+W/dzT8nePIASoQHUCI8gBLhAZQID6BEeAAlwgMoER5AifAASva2Ybo9yBqmu+N8AfEbq+fx7E+Xn0dzx5PL+MyDPlts+8nqND7z1TJvI6ZtyNuyPcq+bpd386XGL3+cLwvurrL3H35MrbXWLh5kc/1V/p76z0e0dg+yNm43yVu7KU8eQInwAEqEB1AiPIAS4QGUCA+gRHgAJcIDKBEeQInwAEr2t54+z+q8/SLvEj8+ehHPvn3wZTS36i/iM692s2ju3iI/88XhiGW9s7winer6/MxtWKW+GlFP7w7znyfEd+p+uFS4tbZ9kX2mu3n+T+3ybl4lP/o0WwC+2+b3KeXJAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkDJ3tbTd+GVzeZ5Pf31+ct49tEkq7Kv+uv4zCezbHv76Tyvp+/mI+rp05uvpw+7/PWvV9nfqmHEou/uWVYPb621ycNs0/39u/n35Iuvs/Xp28P4yLYd8TOC9b1se/50xM8IUp48gBLhAZQID6BEeAAlwgMoER5AifAASoQHUCI8gJI9bphmjbjZLF/sejrJm5un/VU0t+qzBbSttXbSZw3HxTRvrQ7TvOE59Lfwt2LI3//0MrvW65P8PXWvZ59Ta63dOTmP5jbbvOLaP8g+08vJQXzmwbP89S8ezKO5VXxizpMHUCI8gBLhAZQID6BEeAAlwgMoER5AifAASoQHUCI8gJK9raensTab5PX0RVg5by2vnS+7PH9XfVaPP5qs4zNbP6KefvM7cFs3yavU62V2r7ar/DM9XuSf6b2jrJ4+xp2j7DP9aJMtSm6ttbbL7+nsLLtXYxZVpzx5ACXCAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAyjZ23r6ENfT8+3dyxH19MMu63IfdPktnHVZlXjW5e9pTPyn9/S2rBdhP767+Sp1a62dHmRV8keH38RnPppns/96fhKf+erNfNP6ycfZPe36m/9tgicPoER4ACXCAygRHkCJ8ABKhAdQIjyAEuEBlAgPoGR/G6ZhIW4SLipuLW94/nc2y9VZly+rnbdNNDft8+u8rTbmbRjCW9Wf5/f0V48+jWdPplnD+BfLz+Iz//z0J9lrLy7jM7/qV/HsbnYLW61DnjyAEuEBlAgPoER4ACXCAygRHkCJ8ABKhAdQIjyAEuEBlOxtPT2NtcmIevasy+rhrbU2a1lFum95PThdbDymRj8q/r+7JnNrrbX1cXgBD/Iq92aXV9l/f+fDaK5v+U8efnfno2juyeU78ZlfzPPv9OYou6fDdsR3KuTJAygRHkCJ8ABKhAdQIjyAEuEBlAgPoER4ACXCAygRHkDJ3tbT0+3ps0leu52PqH1PuuwCJuGW9dZa61tWO+7HbEQfMZve0zHG1J7TJvlkmp/5mzv/iGcfTL6J5s52B/GZ96avork3ls/jM/+x/WE8G/7iobUR39OUJw+gRHgAJcIDKBEeQInwAEqEB1AiPIAS4QGUCA+gZH8bpuGVzfu8jThmse1tSJc1j1mA3PVj2qj56IgLyEfDSz1eXMVnfnp9N5795dE/o7nfHr6Mz/zLZfb+n1wt4zOH6YjPNP1Qh5v/7nvyAEqEB1AiPIAS4QGUCA+gRHgAJcIDKBEeQInwAEqEB1Cyt/X07TybW87yKvOYBcjrIZvtbyF/F/11PNvP8trxdnbz/fSuz89chw3txZgFyMd/j2d/NMmWFX+Rv3x7vl1Ec8fT/Hs6HG/i2etV9g+lm4Tbp0fw5AGUCA+gRHgAJcIDKBEeQInwAEqEB1AiPIAS4QGUCA+gZG/r6Vf3s9r1W8sn8ZmXwyye/WSTvf5hdxGf+XKXVYnvTbMadWutPX7tRf76i6xKPcawzbvc13eye/rm6dP4zM/W+fb0x9Nn0dyqW8dnpt5efh3PfvyD/D19s3oUzY35nFKePIAS4QGUCA+gRHgAJcIDKBEeQInwAEqEB1AiPICSbhiGb+3F3u3fi1/sDx8+v81L4X/448/v5MN9vlj313/NFjtPunyp82zEUutn66xhe9DnC4jfPMyaoy+2R/GZuyH/m96H9+pP7+Sf6Qeb96Ot1p48gBLhAZQID6BEeAAlwgMoER5AifAASoQHUCI8gBLhAZR8q/V04PvDkwdQIjyAEuEBlAgPoER4ACXCAygRHkCJ8ABKhAdQIjyAkv8AXazbaPB/J7sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1286cd710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## %matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "plt.matshow(x_array[0,:,:,:].reshape(21,22))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = x_array[0,:,:,11:].reshape(21,11)\n",
    "str_txt = \"\"\n",
    "for i in range(21):\n",
    "    for j in range(11):\n",
    "        str_txt = str_txt + str(txt[i,j]) + \" \"\n",
    "    str_txt = str_txt +\"\\n\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Output.txt\", \"w\")\n",
    "text_file.write(str_txt)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
