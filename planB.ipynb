{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ( \"mesh_input.txt\" , 'r')\n",
    "input_data = []\n",
    "input_data = [line.split() for line in f]\n",
    "mesh_input = np.array([])\n",
    "mesh_input.resize((21,21))\n",
    "for i in range(len(input_data)):\n",
    "    col = int(input_data[i][0])\n",
    "    row = int(input_data[i][1])\n",
    "    val = float(input_data[i][2])\n",
    "    mesh_input[col][row] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_all = glob.glob(\"traindata/*.txt\")\n",
    "list_in = []\n",
    "list_out = []\n",
    "for filename in filename_all:\n",
    "    para = filename.split(\"_\")\n",
    "    D = para[1]\n",
    "    K = para[2]\n",
    "    t = para[3].split(\".txt\")[0]\n",
    "    f = open ( filename , 'r')\n",
    "    row_data = []\n",
    "    row_data = [line.split() for line in f]\n",
    "\n",
    "    matrix_output = np.array([])\n",
    "    matrix_output.resize((1,21,21))\n",
    "    matrix_input = np.array([])\n",
    "    matrix_input.resize((4,21,21))\n",
    "    \n",
    "    for i in range(len(row_data)):\n",
    "        col = int(row_data[i][0])\n",
    "        row = int(row_data[i][1])\n",
    "        val = float(row_data[i][2])\n",
    "        matrix_output[0][col][row] = val\n",
    "        \n",
    "#     matrix_input[0]=-1\n",
    "#     matrix_input[0,20,1:19] = 2/3\n",
    "#     matrix_input[0,:,0] = 0\n",
    "#     matrix_input[0,:,20] = 0\n",
    "#     matrix_input[0,0,:] = 0\n",
    "    matrix_input[0] = np.copy(mesh_input)\n",
    "    matrix_input[1] = D\n",
    "    matrix_input[2] = K\n",
    "    matrix_input[3] = t\n",
    "    list_in.append(matrix_input)\n",
    "    list_out.append(matrix_output)\n",
    "arr_in = np.array(list_in)\n",
    "arr_out = np.array(list_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = []\n",
    "train_out = []\n",
    "test_in = []\n",
    "test_out = []\n",
    "for i in range(400):\n",
    "    arr_train_in = np.copy(arr_in[(5*i):(5*i+5),:,:,:])\n",
    "    ten_train_in = torch.from_numpy(arr_train_in)\n",
    "    train_in.append(ten_train_in)\n",
    "    \n",
    "    arr_train_out = np.copy(arr_out[(5*i):(5*i+5),:,:,:]) \n",
    "    ten_train_out = torch.from_numpy(arr_train_out)\n",
    "    train_out.append(ten_train_out)\n",
    "    \n",
    "for i in range(50):\n",
    "    arr_test_in = np.copy(arr_in[(5*i+2000):(5*i+2005),:,:,:])\n",
    "    ten_test_in = torch.from_numpy(arr_test_in)\n",
    "    test_in.append(ten_test_in)\n",
    "    \n",
    "    arr_test_out = np.copy(arr_out[(5*i+2000):(5*i+2005),:,:,:])\n",
    "    ten_test_out = torch.from_numpy(arr_test_out)\n",
    "    test_out.append(ten_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:72: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/15], loss:0.0112\n",
      "epoch [2/15], loss:0.0059\n",
      "epoch [3/15], loss:0.0034\n",
      "epoch [4/15], loss:0.0016\n",
      "epoch [5/15], loss:0.0012\n",
      "epoch [6/15], loss:0.0009\n",
      "epoch [7/15], loss:0.0008\n",
      "epoch [8/15], loss:0.0007\n",
      "epoch [9/15], loss:0.0007\n",
      "epoch [10/15], loss:0.0007\n",
      "epoch [11/15], loss:0.0007\n",
      "epoch [12/15], loss:0.0007\n",
      "epoch [13/15], loss:0.0007\n",
      "epoch [14/15], loss:0.0007\n",
      "epoch [15/15], loss:0.0007\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./dc_img'):\n",
    "    os.mkdir('./dc_img')\n",
    "\n",
    "\n",
    "# def to_img(x):\n",
    "#     x = 0.5 * (x + 1)\n",
    "#     x = x.clamp(0, 1)\n",
    "#     x = x.view(x.size(0), 1, 28, 28)\n",
    "#     return x\n",
    "\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# img_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# dataset = MNIST('./data', transform=img_transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 3, stride=2, padding=0),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 2, stride=2),  # b, 8, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2),  # b, 1, 21, 21\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(train_in)):\n",
    "        img = train_in[i]\n",
    "        img = img.float()\n",
    "        ground_truth = train_out[i]\n",
    "        ground_truth = ground_truth.float()\n",
    "        img = Variable(img).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, ground_truth)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "#         pic = to_img(output.cpu().data)\n",
    "        save_image(output, './dc_img/image_{}.png'.format(epoch))\n",
    "\n",
    "# torch.save(model.state_dict(), './conv_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./test_img'):\n",
    "    os.mkdir('./test_img')\n",
    "for i in range(len(test_in)):\n",
    "    img = test_in[i]\n",
    "    img = test_in[i].float()\n",
    "    ground_truth = test_out[i]\n",
    "    ground_truth = ground_truth.float()\n",
    "    img = Variable(img).to(device)\n",
    "\n",
    "    output = model(img)\n",
    "    loss = criterion(output, ground_truth)\n",
    "\n",
    "    save_image(output, './test_img/image_{}.png'.format(i))\n",
    "    save_image(ground_truth, './test_img/ground_truth_{}.png'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
